"""
Test Case: TC-F-003-07
Requirement: F-003 - Implement batch processing with internal summaries for AI insights
Description: Verify final verdict prompt contains all batch summaries with proper formatting
Generated: 2025-10-01T14:59:00Z
"""

import sqlite3
import time
from unittest.mock import patch

def test_TC_F_003_07():
    """Verify final verdict prompt includes all batch summaries"""

    db_path = "/home/javiervel/clients/bosenet/ai-timesheet/inference/docker_files_api_copy2/shared/data/inference_results.db"

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        # Clear database first
        cursor.execute("DELETE FROM inference_results")
        cursor.execute("DELETE FROM ai_insights WHERE insight_type = 'pattern_analysis'")
        conn.commit()

        # Insert 1000 records (2 batches)
        for i in range(1000):
            cursor.execute("""
                INSERT INTO inference_results
                (sentence, answer, reason, mode, score, timestamp, batch_id)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                f"TC-F-003-07 prompt test {i}",
                "accepted", "", "BERT", 0.90, time.time(), None
            ))

        conn.commit()

        # Import AIInsightsGenerator
        import sys
        sys.path.insert(0, '/home/javiervel/clients/bosenet/ai-timesheet/inference/docker_files_api_copy2/dashboard/src')
        from ai_insights import AIInsightsGenerator

        generator = AIInsightsGenerator(db_path)

        # Capture prompts sent to Gemini API
        captured_prompts = []

        class MockResponse:
            def __init__(self, text):
                self.text = text
                self.candidates = [self]
                self.content = self
                self.parts = [self]

        def mock_generate_content(prompt):
            captured_prompts.append(prompt)
            return MockResponse(f"Mock response {len(captured_prompts)}")

        with patch.object(generator.model, 'generate_content', side_effect=mock_generate_content):
            result = generator.generate_pattern_analysis()

        # Should have 3 prompts: 2 batch summaries + 1 final verdict
        assert len(captured_prompts) == 3, f"Expected 3 prompts (2 batch + 1 final), got {len(captured_prompts)}"

        # Get the final verdict prompt (last one)
        final_prompt = captured_prompts[-1]

        # Verify final prompt contains batch summaries
        assert "Batch 1" in final_prompt or "batch 1" in final_prompt.lower(), "Final prompt should mention Batch 1"
        assert "Batch 2" in final_prompt or "batch 2" in final_prompt.lower(), "Final prompt should mention Batch 2"

        # Verify format mentions multiple batches
        assert "batch summaries" in final_prompt.lower() or "batches" in final_prompt.lower(), \
            "Final prompt should reference batch summaries"

        print(f"✓ Captured {len(captured_prompts)} prompts total")
        print(f"✓ Final verdict prompt contains 'Batch 1' and 'Batch 2' references")
        print(f"✓ Prompt formatting verified:")
        print(f"  - Batch 1: {'✓' if 'Batch 1' in final_prompt else 'X'}")
        print(f"  - Batch 2: {'✓' if 'Batch 2' in final_prompt else 'X'}")
        print(f"  - Format: Consolidates {len(captured_prompts)-1} batch summaries")

    finally:
        cursor.execute("DELETE FROM inference_results WHERE sentence LIKE 'TC-F-003-07%'")
        conn.commit()
        conn.close()

if __name__ == "__main__":
    try:
        test_TC_F_003_07()
        print("TC-F-003-07: PASSED")
    except AssertionError as e:
        print(f"TC-F-003-07: FAILED - {e}")
    except Exception as e:
        print(f"TC-F-003-07: ERROR - {e}")
