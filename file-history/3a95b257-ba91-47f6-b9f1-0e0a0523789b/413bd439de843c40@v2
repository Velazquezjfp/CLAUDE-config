#!/usr/bin/env python3
"""
AI Inference Dashboard - Flask Application
Simple analytics dashboard for inference tracking
"""
import os
import sys
import sqlite3
import json
from datetime import datetime, timedelta
from flask import Flask, render_template, jsonify, request, send_file
from collections import Counter
import tempfile
import csv

# Add parent directory to path to import db_manager
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import AI insights generator
from ai_insights import AIInsightsGenerator

class PrefixMiddleware(object):
    def __init__(self, app, prefix=''):
        self.app = app
        self.prefix = prefix

    def __call__(self, environ, start_response):
        if environ['PATH_INFO'].startswith(self.prefix):
            environ['PATH_INFO'] = environ['PATH_INFO'][len(self.prefix):]
            environ['SCRIPT_NAME'] = self.prefix
            return self.app(environ, start_response)
        else:
            start_response('404 Not Found', [('Content-Type', 'text/plain')])
            return [b"This URL does not belong to the application."]

# Get the application prefix from environment variable, default to empty string for local development
APP_PREFIX = os.getenv('FLASK_APP_PREFIX', '')

app = Flask(__name__, template_folder='../templates', static_folder='../static')

# If a prefix is set, configure Flask's application root and apply the middleware
if APP_PREFIX:
    app.config['APPLICATION_ROOT'] = APP_PREFIX
    app.wsgi_app = PrefixMiddleware(app.wsgi_app, prefix=APP_PREFIX)

# Database configuration using shared volume
DATABASE_PATH = os.getenv('DATABASE_PATH', '../shared/data/inference_results.db')

class DashboardDB:
    def __init__(self):
        self.db_path = DATABASE_PATH
        
    def get_connection(self):
        """Get database connection"""
        return sqlite3.connect(self.db_path, check_same_thread=False)
    
    def get_recent_inferences(self, limit=100):
        """Get recent inference results"""
        with self.get_connection() as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute('''
                SELECT * FROM inference_results 
                ORDER BY timestamp DESC 
                LIMIT ?
            ''', (limit,))
            return [dict(row) for row in cursor.fetchall()]
    
    def get_daily_stats(self, days=30):
        """Get daily statistics"""
        with self.get_connection() as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute('''
                SELECT 
                    DATE(timestamp) as date,
                    COUNT(*) as total_inferences,
                    SUM(CASE WHEN answer = 'accepted' THEN 1 ELSE 0 END) as accepted,
                    SUM(CASE WHEN answer = 'rejected' THEN 1 ELSE 0 END) as rejected,
                    AVG(CASE WHEN score IS NOT NULL THEN score END) as avg_bert_score,
                    SUM(CASE WHEN mode = 'BERT' THEN 1 ELSE 0 END) as bert_count,
                    SUM(CASE WHEN mode = 'LLM' THEN 1 ELSE 0 END) as llm_count
                FROM inference_results 
                WHERE timestamp >= datetime('now', '-' || ? || ' days')
                GROUP BY DATE(timestamp)
                ORDER BY date DESC
            ''', (days,))
            return [dict(row) for row in cursor.fetchall()]
    
    def get_rejection_reasons(self, limit=50):
        """Get most common rejection reasons"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT reason, COUNT(*) as count
                FROM inference_results 
                WHERE answer = 'rejected' AND reason != ''
                GROUP BY reason 
                ORDER BY count DESC 
                LIMIT ?
            ''', (limit,))
            return cursor.fetchall()
    
    def get_mode_distribution(self):
        """Get BERT vs LLM usage distribution"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT mode, COUNT(*) as count
                FROM inference_results 
                GROUP BY mode
            ''')
            return dict(cursor.fetchall())
    
    def get_score_distribution(self):
        """Get BERT score distribution"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT
                    ROUND(score, 1) as score_bucket,
                    COUNT(*) as count
                FROM inference_results
                WHERE score IS NOT NULL AND mode = 'BERT'
                GROUP BY ROUND(score, 1)
                ORDER BY score_bucket
            ''')
            return cursor.fetchall()

    def get_total_count(self):
        """Get total count of all inference results"""
        with self.get_connection() as conn:
            cursor = conn.execute('SELECT COUNT(*) as total FROM inference_results')
            return cursor.fetchone()[0]

    def get_answer_counts(self):
        """Get total accepted and rejected counts"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT
                    SUM(CASE WHEN answer = 'accepted' THEN 1 ELSE 0 END) as accepted,
                    SUM(CASE WHEN answer = 'rejected' THEN 1 ELSE 0 END) as rejected
                FROM inference_results
            ''')
            result = cursor.fetchone()
            return {'accepted': result[0] or 0, 'rejected': result[1] or 0}

    def export_data(self, format='json', date_from=None, date_to=None, answer_filter=None):
        """Export inference data"""
        query = 'SELECT * FROM inference_results WHERE 1=1'
        params = []
        
        if date_from:
            query += ' AND timestamp >= ?'
            params.append(date_from)
        if date_to:
            query += ' AND timestamp <= ?'
            params.append(date_to)
        if answer_filter:
            query += ' AND answer = ?'
            params.append(answer_filter)
        
        query += ' ORDER BY timestamp DESC'
        
        with self.get_connection() as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(query, params)
            rows = [dict(row) for row in cursor.fetchall()]
            
            return rows

# Initialize database connection
db = DashboardDB()

# Initialize AI insights generator
try:
    ai_insights = AIInsightsGenerator(DATABASE_PATH)
except Exception as e:
    print(f"‚ö†Ô∏è  AI Insights not available: {e}")
    ai_insights = None

@app.route('/')
def dashboard():
    """Main dashboard page"""
    return render_template('dashboard.html')

@app.route('/api/stats')
def api_stats():
    """Get dashboard statistics"""
    try:
        # Get recent data
        recent = db.get_recent_inferences(100)
        daily_stats = db.get_daily_stats(30)
        mode_dist = db.get_mode_distribution()
        rejection_reasons = db.get_rejection_reasons(10)
        score_dist = db.get_score_distribution()

        # Calculate summary stats
        total_inferences = db.get_total_count()
        answer_counts = db.get_answer_counts()
        accepted_count = answer_counts['accepted']
        rejected_count = answer_counts['rejected']
        acceptance_rate = (accepted_count / total_inferences * 100) if total_inferences > 0 else 0
        
        # Average scores
        bert_scores = [r['score'] for r in recent if r['score'] is not None and r['mode'] == 'BERT']
        avg_bert_score = sum(bert_scores) / len(bert_scores) if bert_scores else 0
        
        # Get AI insights
        insights = {}
        if ai_insights:
            try:
                insights = ai_insights.get_all_insights()
            except Exception as e:
                insights = {'error': f'Insights temporarily unavailable: {str(e)[:50]}...'}

        return jsonify({
            'summary': {
                'total_inferences': total_inferences,
                'accepted_count': accepted_count,
                'rejected_count': rejected_count,
                'acceptance_rate': round(acceptance_rate, 1),
                'avg_bert_score': round(avg_bert_score, 3),
                'bert_usage': mode_dist.get('BERT', 0),
                'llm_usage': mode_dist.get('LLM', 0)
            },
            'daily_stats': daily_stats,
            'mode_distribution': mode_dist,
            'rejection_reasons': [{'reason': r[0], 'count': r[1]} for r in rejection_reasons],
            'score_distribution': [{'score': r[0], 'count': r[1]} for r in score_dist],
            'recent_inferences': recent[:20],  # Last 20 for display
            'ai_insights': insights
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/export')
def api_export():
    """Export data endpoint"""
    try:
        format_type = request.args.get('format', 'json')
        date_from = request.args.get('date_from')
        date_to = request.args.get('date_to')
        answer_filter = request.args.get('answer_filter')
        
        data = db.export_data(format_type, date_from, date_to, answer_filter)
        
        if format_type == 'csv':
            # Create temporary CSV file
            temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv')
            if data:
                fieldnames = data[0].keys()
                writer = csv.DictWriter(temp_file, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(data)
            temp_file.close()
            
            return send_file(temp_file.name, as_attachment=True, 
                           download_name=f'inference_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
        else:
            return jsonify(data)
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/config')
def api_config():
    """Get frontend configuration including app prefix"""
    return jsonify({
        'app_prefix': APP_PREFIX
    })

@app.route('/health')
def health():
    """Health check endpoint"""
    try:
        # Test database connection
        with db.get_connection() as conn:
            cursor = conn.execute('SELECT COUNT(*) FROM inference_results')
            count = cursor.fetchone()[0]
        
        return jsonify({
            'status': 'healthy',
            'database': 'connected',
            'total_records': count,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

if __name__ == '__main__':
    import os
    
    # Get environment settings
    environment = os.getenv('FLASK_ENV', 'production')
    is_production = environment == 'production'
    
    print("üöÄ Starting AI Inference Dashboard...")
    print(f"üìä Database path: {os.path.abspath(DATABASE_PATH)}")
    print(f"üåê Environment: {environment}")
    print("üåê Dashboard will be available at: http://localhost:8001")
    
    # Ensure database exists
    if not os.path.exists(DATABASE_PATH):
        print("‚ö†Ô∏è  Database file not found. Make sure the inference API has been run first.")
    
    # Configure for production or development
    if is_production:
        print("‚úÖ Running in production mode")
        app.run(host='0.0.0.0', port=8001, debug=False)
    else:
        print("‚ö†Ô∏è  Running in development mode")
        app.run(host='0.0.0.0', port=8001, debug=True)
