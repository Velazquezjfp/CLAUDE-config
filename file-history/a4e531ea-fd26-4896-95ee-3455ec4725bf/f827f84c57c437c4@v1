"""
AI Insights Generator for Dashboard
Uses Gemini Flash 2.0 to analyze inference patterns and provide actionable insights
"""
import os
import sqlite3
import json
import google.generativeai as genai
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class AIInsightsGenerator:
    def __init__(self, db_path: str):
        self.db_path = db_path
        
        # Initialize Gemini API
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment variables")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Initialize insights database
        self.init_insights_table()
    
    def init_insights_table(self):
        """Create insights table if it doesn't exist"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS ai_insights (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    insight_type TEXT NOT NULL,
                    content TEXT NOT NULL,
                    metadata TEXT,
                    expires_at DATETIME
                )
            ''')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_insights_type ON ai_insights(insight_type)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_insights_expires ON ai_insights(expires_at)')
    
    def get_cached_insight(self, insight_type: str) -> Optional[Dict]:
        """Get cached insight if still valid"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute('''
                SELECT * FROM ai_insights 
                WHERE insight_type = ? AND expires_at > datetime('now')
                ORDER BY timestamp DESC LIMIT 1
            ''', (insight_type,))
            
            row = cursor.fetchone()
            if row:
                return {
                    'content': row['content'],
                    'timestamp': row['timestamp'],
                    'metadata': json.loads(row['metadata']) if row['metadata'] else {}
                }
        return None
    
    def store_insight(self, insight_type: str, content: str, metadata: Dict = None, hours_valid: int = 3):
        """Store insight in database with expiration"""
        expires_at = datetime.now() + timedelta(hours=hours_valid)
        metadata_json = json.dumps(metadata) if metadata else None
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT INTO ai_insights (insight_type, content, metadata, expires_at)
                VALUES (?, ?, ?, ?)
            ''', (insight_type, content, metadata_json, expires_at))
    
    def sample_recent_data(self, limit: int = 100) -> Dict[str, Any]:
        """Intelligently sample recent inference data"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            # Get recent data
            recent_cursor = conn.execute('''
                SELECT * FROM inference_results 
                ORDER BY timestamp DESC LIMIT ?
            ''', (limit,))
            recent_data = [dict(row) for row in recent_cursor.fetchall()]
            
            if not recent_data:
                return {'summary': 'No data available'}
            
            # Calculate summary statistics
            total = len(recent_data)
            accepted = sum(1 for r in recent_data if r['answer'] == 'accepted')
            rejected = total - accepted
            bert_usage = sum(1 for r in recent_data if r['mode'] == 'BERT')
            llm_usage = total - bert_usage
            
            # Get average scores for BERT
            bert_scores = [r['score'] for r in recent_data if r['score'] is not None and r['mode'] == 'BERT']
            avg_bert_score = sum(bert_scores) / len(bert_scores) if bert_scores else 0
            
            # Sample rejection reasons (top 5 most common)
            rejection_reasons = [r['reason'] for r in recent_data if r['answer'] == 'rejected' and r['reason']]
            from collections import Counter
            common_reasons = Counter(rejection_reasons).most_common(5)
            
            # Get time range
            time_range = f"{recent_data[-1]['timestamp']} to {recent_data[0]['timestamp']}"
            
            return {
                'summary': {
                    'total_inferences': total,
                    'accepted': accepted,
                    'rejected': rejected,
                    'acceptance_rate': round(accepted/total*100, 1),
                    'bert_usage': bert_usage,
                    'llm_usage': llm_usage,
                    'avg_bert_score': round(avg_bert_score, 3),
                    'time_range': time_range
                },
                'common_rejections': common_reasons[:3],  # Top 3 for brevity
                'sample_entries': recent_data[:10]  # First 10 for pattern analysis
            }
    
    def generate_pattern_analysis(self) -> str:
        """Generate insights about classification patterns"""
        # Check cache first
        cached = self.get_cached_insight('pattern_analysis')
        if cached:
            return cached['content']
        
        # Sample recent data
        data = self.sample_recent_data(80)
        
        if 'summary' not in data or isinstance(data['summary'], str):
            insight = "Insufficient data available for pattern analysis."
            self.store_insight('pattern_analysis', insight)
            return insight
        
        # Create focused prompt for Gemini
        prompt = f"""
Analyze this AI activity classification data and provide 3-4 actionable insights in English:

SUMMARY STATS (last 80 inferences):
- Total: {data['summary']['total_inferences']} classifications
- Acceptance Rate: {data['summary']['acceptance_rate']}%
- BERT vs LLM Usage: {data['summary']['bert_usage']} vs {data['summary']['llm_usage']}
- Average BERT Score: {data['summary']['avg_bert_score']}

TOP REJECTION REASONS:
{chr(10).join([f"- {reason} ({count}x)" for reason, count in data['common_rejections']])}

Please provide insights in this format:
1. [Pattern observation and what it means]
2. [Usage trend analysis - BERT vs LLM efficiency]
3. [Quality assessment and recommendations]

Keep insights brief (1-2 sentences each), actionable, and in English. Focus on what the compliance team should know.
"""
        
        try:
            response = self.model.generate_content(prompt)
            insight_content = response.candidates[0].content.parts[0].text.strip()
            
            # Store in cache
            metadata = {'data_points': data['summary']['total_inferences']}
            self.store_insight('pattern_analysis', insight_content, metadata, hours_valid=3)
            
            return insight_content
            
        except Exception as e:
            error_insight = f"AI analysis error: {str(e)[:100]}..."
            self.store_insight('pattern_analysis', error_insight, {'error': True}, hours_valid=1)
            return error_insight
    
    def generate_quality_assessment(self) -> str:
        """Generate quality assessment of recent classifications"""
        # Check cache
        cached = self.get_cached_insight('quality_assessment')
        if cached:
            return cached['content']
        
        data = self.sample_recent_data(60)
        
        if 'summary' not in data or isinstance(data['summary'], str):
            insight = "Insufficient data available for quality assessment."
            self.store_insight('quality_assessment', insight)
            return insight
        
        # Focus on quality indicators
        summary = data['summary']
        uncertain_cases = summary['llm_usage']  # LLM usage indicates uncertainty
        confidence_level = "high" if summary['avg_bert_score'] > 0.85 else "medium" if summary['avg_bert_score'] > 0.7 else "low"
        
        prompt = f"""
Assess the quality of AI classifications based on these metrics:

QUALITY INDICATORS:
- BERT Confidence Score: {summary['avg_bert_score']} (average)
- Uncertain Cases (requiring LLM): {uncertain_cases} out of {summary['total_inferences']}
- Rejection Rate: {100-summary['acceptance_rate']}%

Provide a brief quality assessment (2-3 sentences) in English:
- Is the classification quality good/medium/poor?
- Are there too many uncertain cases?
- What recommendations for improvement?
"""
        
        try:
            response = self.model.generate_content(prompt)
            insight_content = response.candidates[0].content.parts[0].text.strip()
            
            metadata = {
                'avg_score': summary['avg_bert_score'],
                'uncertain_cases': uncertain_cases,
                'confidence_level': confidence_level
            }
            self.store_insight('quality_assessment', insight_content, metadata, hours_valid=4)
            
            return insight_content
            
        except Exception as e:
            error_insight = f"Quality assessment unavailable: {str(e)[:50]}..."
            self.store_insight('quality_assessment', error_insight, {'error': True}, hours_valid=1)
            return error_insight
    
    def get_all_insights(self) -> Dict[str, str]:
        """Get all current insights"""
        insights = {}
        
        # Generate insights (cached if available)
        insights['pattern_analysis'] = self.generate_pattern_analysis()
        insights['quality_assessment'] = self.generate_quality_assessment()
        
        return insights
    
    def cleanup_expired_insights(self):
        """Remove expired insights from database"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("DELETE FROM ai_insights WHERE expires_at < datetime('now')")


# Example usage and testing
if __name__ == "__main__":
    # Test the insights generator
    db_path = "../shared/data/inference_results.db"
    
    if os.path.exists(db_path):
        generator = AIInsightsGenerator(db_path)
        
        print("🧠 Testing AI Insights Generator...")
        print("=" * 50)
        
        insights = generator.get_all_insights()
        
        for insight_type, content in insights.items():
            print(f"\n📊 {insight_type.replace('_', ' ').title()}:")
            print("-" * 30)
            print(content)
        
        print("\n✅ AI Insights test completed!")
    else:
        print("❌ Database not found. Please run the main stack first.")